# UMD SMITH Information Systems Datathon 2022

## Problem Statement: Image Classification
### A picture is worth a thousand words, yet sometimes a few will do. We all rely on online images for knowledge sharing, learning, and understanding. Even the largest websites are missing visual content and metadata to pair with their images. Captions and “alt text” increase accessibility and enable better search. The majority of images on Hearst Database come from various categories and don't have any written context connected to the image. Open models could help anyone improve accessibility and learning for all.

Current solutions rely on simple methods based on translations or page interlinks, which have limited coverage. Even the most advanced computer vision image captioning isn't suitable for images with complex semantics.

In this competition, you’ll build a model that automatically retrieves the text closest to an image. Specifically, you'll train your model to associate given images with article titles or complex captions. The best models will account for the semantic granularity of Hearst images.

If successful, you'll be contributing to the accessibility of one of the largest databases from Hearst. The users will be able to more easily understand, search, and describe media at scale. As a result, you’ll contribute to an open model to improve learning for all.

## Getting Started

### Presentation

* See [Slides](https://github.com/whl0217/UMD_IS_Datathon/blob/main/Image_Classification_Team%205.pptx)
* See [Presentation Recording](https://github.com/whl0217/UMD_IS_Datathon/blob/main/Image_Classification_Team%205.mp4)

### Source code

* See [Image Classifier](https://github.com/whl0217/UMD_IS_Datathon/blob/main/Image_Classification_Team%205.ipynb)

## Authors

* Wang-Han Li <br>
wang-han.li@marylandsmith.umd.edu
 
* Chung-Hao Lee <br>

* Fabienne Yang <br>
